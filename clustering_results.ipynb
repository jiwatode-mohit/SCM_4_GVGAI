{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f0c9db",
   "metadata": {},
   "source": [
    "# GVGAI Description Clustering\n",
    "\n",
    "Normalization → dimensionality reduction → clustering are orchestrated in staged loops so the comparisons stay concise and presentation-ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a9a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Sequence\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from IPython.display import display\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "RANDOM_STATE = 42\n",
    "DEFAULT_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "@dataclass\n",
    "class GameDescription:\n",
    "    identifier: str\n",
    "    description: str\n",
    "\n",
    "def embed_descriptions(items: Sequence[GameDescription], model_name: str = DEFAULT_MODEL_NAME) -> np.ndarray:\n",
    "    model = SentenceTransformer(model_name)\n",
    "    texts = [item.description for item in items]\n",
    "    embeddings = model.encode(texts, convert_to_numpy=True, normalize_embeddings=True, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "def normalize_descriptions(descriptions: Dict[str, str]) -> List[GameDescription]:\n",
    "    items: List[GameDescription] = []\n",
    "    for key, text in descriptions.items():\n",
    "        cleaned = text.strip()\n",
    "        if cleaned:\n",
    "            items.append(GameDescription(key, cleaned))\n",
    "    return items\n",
    "\n",
    "def prepare_game_list(path: Path) -> List[str]:\n",
    "    raw = json.loads(path.read_text())\n",
    "    frame = pd.DataFrame(raw)\n",
    "    return frame.iloc[:, 1].astype(str).str.lower().tolist()\n",
    "\n",
    "def load_description_dict(path: Path) -> Dict[str, str]:\n",
    "    return json.loads(path.read_text())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GAME_LIST_PATH = Path(\"game_list.json\")\n",
    "DESCRIPTION_PATH = Path(\"all_game_descs.json\")\n",
    "\n",
    "whitelist = set(prepare_game_list(GAME_LIST_PATH))\n",
    "raw_descriptions = load_description_dict(DESCRIPTION_PATH)\n",
    "filtered_descriptions = {\n",
    "    key: value\n",
    "    for key, value in raw_descriptions.items()\n",
    "    if not key.lower().startswith('testgame') and key.lower() in whitelist and value\n",
    "}\n",
    "\n",
    "description_items = normalize_descriptions(filtered_descriptions)\n",
    "game_names = [item.identifier for item in description_items]\n",
    "description_vectors = embed_descriptions(description_items)\n",
    "print(f\"Prepared {len(description_items)} descriptions with embedding shape {description_vectors.shape}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZATION_MODES = {\n",
    "    'none': lambda X: X,\n",
    "    'l2': lambda X: Normalizer(norm='l2').fit_transform(X),\n",
    "    'scaling': lambda X: StandardScaler().fit_transform(X),\n",
    "}\n",
    "\n",
    "DIMENSION_REDUCERS = {\n",
    "    \"none\": lambda X: X,\n",
    "    'pca': lambda X: PCA(n_components=min(50, X.shape[1]), random_state=RANDOM_STATE).fit_transform(X),\n",
    "    'umap': lambda X: umap.UMAP(\n",
    "        n_neighbors=15,\n",
    "        min_dist=0.15,\n",
    "        n_components=2,\n",
    "        metric='cosine',\n",
    "        random_state=RANDOM_STATE\n",
    "    ).fit_transform(X),\n",
    "\n",
    "}\n",
    "\n",
    "KMEANS_K_VALUES = list(range(5, 15))\n",
    "KMEANS_INERTIA_RANGE = list(KMEANS_K_VALUES)\n",
    "KMEANS_SILHOUETTE_RANGE = list(KMEANS_K_VALUES)\n",
    "SELECTED_CLUSTER_K = 9  # adjust manually after inspecting the comparison plots\n",
    "\n",
    "DBSCAN_EPS_VALUES = np.round(np.linspace(0.3, 1.5, 7), 2)\n",
    "DBSCAN_MIN_SAMPLES = [3, 5, 10, 15]\n",
    "\n",
    "INCLUDE_CLUSTER_MEDOIDS = True\n",
    "LIST_FULL_CLUSTER_MEMBERS = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea792c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def stage_label(norm_key: str, reducer_key: str) -> str:\n",
    "    return f\"Norm={norm_key.upper()} | DimRed={reducer_key.upper()}\"\n",
    "\n",
    "def evaluate_kmeans(X: np.ndarray, label: str):\n",
    "    inertias: List[float] = []\n",
    "    for k in KMEANS_INERTIA_RANGE:\n",
    "        model = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init='auto')\n",
    "        model.fit(X)\n",
    "        inertias.append(model.inertia_)\n",
    "\n",
    "    silhouettes: List[float] = []\n",
    "    for k in KMEANS_SILHOUETTE_RANGE:\n",
    "        labels = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init='auto').fit_predict(X)\n",
    "        silhouettes.append(silhouette_score(X, labels))\n",
    "\n",
    "    best_idx = int(np.argmax(silhouettes))\n",
    "    best_k = KMEANS_SILHOUETTE_RANGE[best_idx]\n",
    "    best_score = silhouettes[best_idx]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes[0].plot(KMEANS_INERTIA_RANGE, inertias, marker='o')\n",
    "    axes[0].set_title(f'KMeans Elbow | {label}') #### Uncomment here TODO\n",
    "    # axes[0].set_title('KMeans Elbow')\n",
    "    axes[0].set_xlabel('k')\n",
    "    axes[0].set_ylabel('inertia')\n",
    "\n",
    "    axes[1].plot(KMEANS_SILHOUETTE_RANGE, silhouettes, marker='o', label='silhouette')\n",
    "    axes[1].axvline(best_k, color='red', linestyle='--', label=f'peak k={best_k}')\n",
    "    axes[1].set_title(f'KMeans Silhouette | {label}') #### Uncomment here TODO\n",
    "    # axes[1].set_title(f'KMeans Silhouette')\n",
    "    axes[1].set_xlabel('k')\n",
    "    axes[1].set_ylabel('silhouette')\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Peak silhouette {best_score:.3f} at k={best_k}. Inspect manually before choosing k.\")\n",
    "\n",
    "    return {\n",
    "        'k_values': list(KMEANS_SILHOUETTE_RANGE),\n",
    "        'inertias': inertias,\n",
    "        'silhouettes': silhouettes,\n",
    "        'best_k': best_k,\n",
    "        'best_score': best_score,\n",
    "    }\n",
    "\n",
    "def evaluate_dbscan(X: np.ndarray, label: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for eps in DBSCAN_EPS_VALUES:\n",
    "        for min_samples in DBSCAN_MIN_SAMPLES:\n",
    "            model = DBSCAN(eps=float(eps), min_samples=int(min_samples))\n",
    "            labels = model.fit_predict(X)\n",
    "            cluster_ids = np.unique(labels)\n",
    "            cluster_count = int(np.sum(cluster_ids >= 0))\n",
    "            noise_ratio = float(np.mean(labels == -1))\n",
    "            silhouette = silhouette_score(X, labels) if cluster_count > 1 else np.nan\n",
    "            rows.append({\n",
    "                'eps': float(eps),\n",
    "                'min_samples': int(min_samples),\n",
    "                'clusters': cluster_count,\n",
    "                'noise_ratio': noise_ratio,\n",
    "                'silhouette': silhouette,\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    pivot = df.pivot(index='min_samples', columns='eps', values='silhouette')\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.heatmap(pivot, annot=True, fmt='.2f', cmap='crest', cbar_kws={'label': 'silhouette'})\n",
    "    plt.title(f'DBSCAN Silhouette | {label}')\n",
    "    plt.ylabel('min_samples')\n",
    "    plt.xlabel('eps')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return df\n",
    "\n",
    "def summarize_clusters(\n",
    "    labels: np.ndarray,\n",
    "    identifiers: Sequence[str],\n",
    "    vectors: np.ndarray,\n",
    "    *,\n",
    "    include_medoid: bool = False,\n",
    "    show_full_members: bool = False,\n",
    "    top_n: int = 5,\n",
    ") -> pd.DataFrame:\n",
    "    summary_rows = []\n",
    "    label_array = np.asarray(labels)\n",
    "    for cid in sorted(set(label_array)):\n",
    "        if cid < 0:\n",
    "            continue\n",
    "        member_indices = np.where(label_array == cid)[0]\n",
    "        if member_indices.size == 0:\n",
    "            continue\n",
    "        members = [identifiers[idx] for idx in member_indices]\n",
    "        if include_medoid:\n",
    "            cluster_vectors = vectors[member_indices]\n",
    "            centroid = cluster_vectors.mean(axis=0)\n",
    "            distances = np.linalg.norm(cluster_vectors - centroid, axis=1)\n",
    "            medoid_name = members[int(np.argmin(distances))]\n",
    "        else:\n",
    "            medoid_name = None\n",
    "\n",
    "        if show_full_members:\n",
    "            member_str = ', '.join(members)\n",
    "        else:\n",
    "            member_str = ', '.join(members[:top_n])\n",
    "\n",
    "        row = {\n",
    "            'cluster': int(cid),\n",
    "            'size': len(members),\n",
    "            'members': member_str,\n",
    "        }\n",
    "        if include_medoid and medoid_name is not None:\n",
    "            row['medoid'] = medoid_name\n",
    "        summary_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(summary_rows)\n",
    "    ordered_cols = ['cluster', 'size']\n",
    "    if include_medoid:\n",
    "        ordered_cols.append('medoid')\n",
    "    ordered_cols.append('members')\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=ordered_cols)\n",
    "    return df[ordered_cols]\n",
    "\n",
    "def visualize_embedding(\n",
    "    X: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    title: str,\n",
    "    identifiers: Sequence[str] | None = None,\n",
    "    show_center_names: bool = False,\n",
    ") -> None:\n",
    "    label_array = np.asarray(labels)\n",
    "\n",
    "    # Identify non-noise clusters\n",
    "    cluster_ids = sorted({int(cid) for cid in np.unique(label_array) if cid >= 0})\n",
    "\n",
    "    # Compute medoid indices per cluster (in original feature space X)\n",
    "    medoid_indices: Dict[int, int] = {}\n",
    "    for cid in cluster_ids:\n",
    "        member_idx = np.where(label_array == cid)[0]\n",
    "        if member_idx.size == 0:\n",
    "            continue\n",
    "        cluster_vectors = X[member_idx]\n",
    "        centroid = cluster_vectors.mean(axis=0)\n",
    "        distances = np.linalg.norm(cluster_vectors - centroid, axis=1)\n",
    "        medoid_indices[cid] = int(member_idx[int(np.argmin(distances))])\n",
    "\n",
    "    # Dimensionality reduction for visualization\n",
    "    if X.shape[1] > 2:\n",
    "        viz_data = umap.UMAP(\n",
    "            n_neighbors=15,\n",
    "            min_dist=0.15,\n",
    "            n_components=2,\n",
    "            metric='cosine',\n",
    "            random_state=RANDOM_STATE\n",
    "        ).fit_transform(X)\n",
    "        subtitle = ' (UMAP preview)'\n",
    "    else:\n",
    "        viz_data = X\n",
    "        subtitle = ''\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "\n",
    "    # Use a discrete colormap so we can show a legend with cluster numbers\n",
    "    cmap = plt.cm.get_cmap('tab10', len(cluster_ids))\n",
    "\n",
    "    # Plot each cluster separately so legend shows \"Cluster k\" with the right color\n",
    "    for color_idx, cid in enumerate(cluster_ids):\n",
    "        member_mask = (label_array == cid)\n",
    "        plt.scatter(\n",
    "            viz_data[member_mask, 0],\n",
    "            viz_data[member_mask, 1],\n",
    "            s=25,\n",
    "            color=cmap(color_idx),\n",
    "            alpha=0.7,\n",
    "            label=f'{cid}',\n",
    "        )\n",
    "\n",
    "        # Highlight and label the cluster center (medoid)\n",
    "        if cid in medoid_indices:\n",
    "            midx = medoid_indices[cid]\n",
    "            mx, my = viz_data[midx]\n",
    "            plt.scatter(\n",
    "                mx,\n",
    "                my,\n",
    "                marker='*',\n",
    "                s=200,\n",
    "                edgecolors='k',\n",
    "                linewidths=1.2,\n",
    "                color=cmap(color_idx),\n",
    "            )\n",
    "            if identifiers is not None and show_center_names:\n",
    "                plt.annotate(\n",
    "                    identifiers[midx],\n",
    "                    (mx, my),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(5, 5),\n",
    "                    ha='left',\n",
    "                    fontsize=10,\n",
    "                )\n",
    "\n",
    "    # Optional: show noise points (e.g., from DBSCAN) in grey\n",
    "    noise_mask = (label_array < 0)\n",
    "    if np.any(noise_mask):\n",
    "        plt.scatter(\n",
    "            viz_data[noise_mask, 0],\n",
    "            viz_data[noise_mask, 1],\n",
    "            s=15,\n",
    "            color='lightgrey',\n",
    "            alpha=0.5,\n",
    "            label='Noise',\n",
    "        )\n",
    "\n",
    "    # plt.title(f'{title}{subtitle}')\n",
    "    plt.title(f'K-means clustering{subtitle}')\n",
    "    plt.xlabel('component 1')\n",
    "    plt.ylabel('component 2')\n",
    "    plt.xlim(right=3)\n",
    "\n",
    "    # Legend now shows color ↔ cluster number instead of a colorbar\n",
    "    plt.legend(\n",
    "        title='Cluster no.',\n",
    "        loc='center left',\n",
    "        bbox_to_anchor=(1.05, 0.5)\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_records = []\n",
    "kmeans_curve_records = []\n",
    "\n",
    "for norm_name, norm_fn in NORMALIZATION_MODES.items():\n",
    "    normalized = norm_fn(description_vectors)\n",
    "    for reducer_name, reducer_fn in DIMENSION_REDUCERS.items():\n",
    "        reduced = reducer_fn(normalized)\n",
    "        label = stage_label(norm_name, reducer_name)\n",
    "        # label = f\"K-means\"\n",
    "        print()\n",
    "        print(f\"=== {label} ===\")\n",
    "\n",
    "        kmeans_metrics = evaluate_kmeans(reduced, f'{label} | KMEANS')\n",
    "        kmeans_curve_records.append({\n",
    "            'label': label,\n",
    "            'k_values': kmeans_metrics['k_values'],\n",
    "            'inertias': kmeans_metrics['inertias'],\n",
    "            'silhouettes': kmeans_metrics['silhouettes'],\n",
    "        })\n",
    "\n",
    "        silhouette_lookup = dict(zip(kmeans_metrics['k_values'], kmeans_metrics['silhouettes']))\n",
    "        selected_k = max(min(SELECTED_CLUSTER_K, KMEANS_K_VALUES[-1]), KMEANS_K_VALUES[0])\n",
    "        selected_silhouette = silhouette_lookup.get(selected_k, float('nan'))\n",
    "\n",
    "        kmeans_model = KMeans(n_clusters=selected_k, random_state=RANDOM_STATE, n_init='auto')\n",
    "        kmeans_labels = kmeans_model.fit_predict(reduced)\n",
    "        visualize_embedding(\n",
    "        reduced,\n",
    "        kmeans_labels,\n",
    "        f'KMeans k={selected_k} | {label}',\n",
    "        # \"K means clustering\", # Uncomment here, this one is for only one visualization\n",
    "        identifiers=game_names,\n",
    "        show_center_names=True,\n",
    "        )\n",
    "\n",
    "        display(\n",
    "            summarize_clusters(\n",
    "                kmeans_labels,\n",
    "                game_names,\n",
    "                reduced,\n",
    "                include_medoid=INCLUDE_CLUSTER_MEDOIDS,\n",
    "                show_full_members=LIST_FULL_CLUSTER_MEMBERS,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        analysis_records.append({\n",
    "            'normalization': norm_name,\n",
    "            'reduction': reducer_name,\n",
    "            'manual_k': selected_k,\n",
    "            'manual_k_silhouette': selected_silhouette,\n",
    "            'best_k_by_silhouette': kmeans_metrics['best_k'],\n",
    "            'peak_silhouette_score': kmeans_metrics['best_score'],\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f77ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "if kmeans_curve_records:\n",
    "    # 1. Split the records into 3 parts (chunks)\n",
    "    # np.array_split handles the math of dividing uneven lists automatically\n",
    "    batches = np.array_split(kmeans_curve_records, 3)\n",
    "\n",
    "    # 2. Iterate through each batch to create a separate figure\n",
    "    for batch_idx, batch_records in enumerate(batches):\n",
    "        \n",
    "        # Skip empty batches (in case you have fewer than 3 records total)\n",
    "        if len(batch_records) == 0:\n",
    "            continue\n",
    "\n",
    "        n = len(batch_records)\n",
    "        \n",
    "        # Create a new figure for this batch\n",
    "        # We add a main title to distinguish the parts\n",
    "        fig, axes = plt.subplots(n, 2, figsize=(14, 4 * n), sharex='col')\n",
    "        fig.suptitle(f'KMeans Analysis - Part {batch_idx + 1} of 3', fontsize=16, y=1.02)\n",
    "        \n",
    "        if n == 1:\n",
    "            axes = np.array(axes).reshape(1, 2)\n",
    "\n",
    "        for idx, record in enumerate(batch_records):\n",
    "            elbow_ax = axes[idx, 0]\n",
    "            sil_ax = axes[idx, 1]\n",
    "            k_values = record['k_values']\n",
    "            \n",
    "            # Plot Elbow\n",
    "            elbow_ax.plot(k_values, record['inertias'], marker='o')\n",
    "            elbow_ax.set_title(f\"Elbow | {record['label']}\")\n",
    "            elbow_ax.set_ylabel('inertia')\n",
    "            \n",
    "            # Plot Silhouette\n",
    "            sil_ax.plot(k_values, record['silhouettes'], marker='o', color='C1')\n",
    "            sil_ax.set_title(f\"Silhouette | {record['label']}\")\n",
    "            sil_ax.set_ylabel('silhouette')\n",
    "            \n",
    "            # Ensure ticks are visible\n",
    "            elbow_ax.tick_params(axis='both', which='both', labelbottom=True)\n",
    "            sil_ax.tick_params(axis='both', which='both', labelbottom=True)\n",
    "\n",
    "        # Set x-labels for the bottom row of this specific figure\n",
    "        for ax in axes[:, 0]:\n",
    "            ax.set_xlabel('k')\n",
    "        for ax in axes[:, 1]:\n",
    "            ax.set_xlabel('k')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print('No KMeans curves recorded. Run the analysis loop first.')\n",
    "\n",
    "# The summary dataframe remains unchanged as it aggregates all data\n",
    "summary_df = pd.DataFrame(analysis_records).sort_values(\n",
    "    ['manual_k_silhouette', 'peak_silhouette_score'], ascending=False\n",
    ")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0c1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
